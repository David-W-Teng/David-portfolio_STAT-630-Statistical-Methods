---
output:
  pdf_document: default
  html_document: default
  word_document: default
---
1.

```{r}
set.seed(01052001)
p <- 0.05
n_samp <- 10000
samp_sizes <- c(15, 30, 50)

samp <- function(n, p, n_samp) {
  replicate(n_samp, rbinom(1, n, p))
}

samp_15 <- samp(15, p, n_samp)
samp_30 <- samp(30, p, n_samp)
samp_50 <- samp(50, p, n_samp)
```

2. (a)

```{r}
results <- sapply(samp_sizes, function(n) {
  samp <- samp(n, p, n_samp)  # Use the samp() function defined earlier
  c(Mean = mean(samp), Standard_Error = sd(samp))
})


means_and_se <- data.frame(
  Sample_Size = samp_sizes,
  Mean = results["Mean", ],
  Standard_Error = results["Standard_Error", ]
)
print(means_and_se)
```

2. (b)

```{r}
set.seed(01052001)
p <- 0.05
n_samp <- 10000
samp_sizes <- c(15, 30, 50)

get_stats <- function(n) {
  samp <- replicate(n_samp, mean(rbinom(n, size = 1, prob = p)))
  c(Mean = mean(samp), SD = sd(samp))
}

stats <- sapply(samp_sizes, get_stats)

mean_diff <- diff(stats["Mean", ])
sd_diff <- diff(stats["SD", ])

# Print results
cat("Mean Differences:", mean_diff, "\n")
cat("Standard Deviation Differences:", sd_diff, "\n")

```

2. (c)

```{r}
theo_stats <- data.frame(
  "Sample_Size" = samp_sizes,
  "Theoretical_Mean" = samp_sizes * p,
  "Theoretical_SE" = sqrt(samp_sizes * p * (1 - p)) / sqrt(samp_sizes)
)
theo_stats
```

The empirical and theoretical means should closely match for p=0.05, as both are based on the same probability. Similarly, the empirical and theoretical standard errors should align, with minor differences due to random variation. As the sample size increases, empirical values converge to theoretical ones, consistent with the law of large numbers.

3. (a)

```{r}
get_percentiles <- function(n) {
  samp <- replicate(n_samp, mean(rbinom(n, size = 1, prob = p)))
  quantile(samp, probs = c(0.25, 0.75))
}
percentiles <- sapply(samp_sizes, get_percentiles)

results <- data.frame(
  Sample_Size = samp_sizes,
  "25th_Percentile" = percentiles["25%", ],
  "75th_Percentile" = percentiles["75%", ]
)
results
```


3. (b)

```{r}
p <- 0.05
samp_sizes <- c(15, 30, 50)

get_true_quartiles <- function(n, p) {
  se <- sqrt(p * (1 - p) / n)
  q25 <- p + qnorm(0.25) * se
  q75 <- p + qnorm(0.75) * se
  c(True_25th = q25, True_75th = q75)
}

true_quartiles <- sapply(samp_sizes, get_true_quartiles, p)

results <- data.frame(
  Sample_Size = samp_sizes,
  True_25th_Percentile = true_quartiles["True_25th", ],
  True_75th_Percentile = true_quartiles["True_75th", ]
)

results
```

3. (c)
True quartiles are based on the normal approximation of the binomial distribution, while empirical quartiles come from simulated data. As sample size increases, empirical quartiles should better match true quartiles. Smaller samples may show larger deviations because of random variation.

4.

```{r}
library(ggplot2)
library(gridExtra)

generate_proportions <- function(n) {
  rbinom(n_samp, n, p) / n
}

proportions_15 <- generate_proportions(15)
proportions_30 <- generate_proportions(30)
proportions_50 <- generate_proportions(50)

plot_histogram <- function(proportions, n) {
  
  ggplot(data.frame(proportions), aes(x = proportions)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black") +
    geom_vline(xintercept = mean(proportions), color = "red", linetype = "dashed") +
    ggtitle(paste("Sample Size =", n)) +
    theme_minimal()
}

hist_15 <- plot_histogram(proportions_15, 15)
hist_30 <- plot_histogram(proportions_30, 30)
hist_50 <- plot_histogram(proportions_50, 50)

grid.arrange(hist_15, hist_30, hist_50, ncol = 3)
```

5. 

```{r}
generate_qqplot <- function(samp, n) {
  qqnorm(samp, main = paste("QQ Plot - Sample Size", n))
  qqline(samp, col = "red")
}

par(mfrow = c(1, 3))  
generate_qqplot(samp(15, p, n_samp), 15)
generate_qqplot(samp(30, p, n_samp), 30)
generate_qqplot(samp(50, p, n_samp), 50)

```

6. 
The Central Limit Theorem (CLT) states that for large sample sizes, the sampling distribution of the sample proportion approximates normality. When p=0.05, the CLT's accuracy depends on sample size. Small samples like n=15 deviate from normality, while larger samples such as n=30 and n=50 show more normal distributions. This demonstrates the CLT's reliability with larger samples.

```{r}
# Load the data
download.file("http://www.openintro.org/stat/data/atheism.RData", destfile =
"atheism.RData")
load("atheism.RData")
```

7. 

```{r}
selected_nationality <- "Canada" 

subset_data <- subset(atheism, nationality == selected_nationality & year == 2012)

head(subset_data)
```

8. 

```{r}
samp_size <- nrow(subset_data)

atheist_count <- sum(subset_data$response == "atheist")
samp_proportion <- atheist_count / samp_size

cat("Sample Size:", samp_size, "\n")
cat("Sample Proportion of Atheists:", samp_proportion, "\n")
```

9. (a)
It is reasonable to assume independence if participants were randomly selected and the sample size represents a small fraction of the total population

9. (b)

```{r}
p_hat <- mean(subset_data$response == "atheist")

n <- nrow(subset_data)

successes <- n * p_hat
failures <- n * (1 - p_hat)

cat("Successes:", successes, "\n")
cat("Failures:", failures, "\n")
```



10.

```{r}
p_hat <- mean(subset_data$response == "atheist")
n <- nrow(subset_data)
se <- sqrt(p_hat * (1 - p_hat) / n)
z <- 1.96  # for 95% confidence

ci <- p_hat + c(-1, 1) * z * se
ci
```

My interpretation: The interval suggests that we are 95% confident that the true proportion of atheists in the chosen nationality in 2012 lies within this range.

